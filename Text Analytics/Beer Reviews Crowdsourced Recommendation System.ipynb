{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0zZZBZ1hnsuk",
    "outputId": "8bc5940e-1052-4498-f507-83444759e80b"
   },
   "source": [
    "# <p style=\"text-align: center;\">MIS 284N: Analytics for Unstructured Data</p>\n",
    "# <p style=\"text-align: center;\">Assignment 2 (Crowdsourced Recommendation System)</p>\n",
    "## <p style=\"text-align: center;\">Ally McNulty (agm3734), Chaitra Setty (cs63687), Emilio Cabrera (eac4622), Vishu Agarwal (va7729), Yashpreet Kaur (yk8742)</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "sKaFjtOAnEyj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-md==3.1.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-3.1.0/en_core_web_md-3.1.0-py3-none-any.whl (45.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 45.4 MB 32.7 MB/s eta 0:00:01    |█████████████▏                  | 18.7 MB 4.7 MB/s eta 0:00:06\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.2.0,>=3.1.0 in ./opt/anaconda3/lib/python3.8/site-packages (from en-core-web-md==3.1.0) (3.1.3)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in ./opt/anaconda3/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (3.0.5)\n",
      "Requirement already satisfied: numpy>=1.15.0 in ./opt/anaconda3/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (1.20.1)\n",
      "Requirement already satisfied: jinja2 in ./opt/anaconda3/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (2.11.3)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in ./opt/anaconda3/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (1.0.5)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in ./opt/anaconda3/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (1.8.2)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in ./opt/anaconda3/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (2.0.5)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in ./opt/anaconda3/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (0.8.2)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in ./opt/anaconda3/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (2.0.6)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in ./opt/anaconda3/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (2.25.1)\n",
      "Requirement already satisfied: packaging>=20.0 in ./opt/anaconda3/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (20.9)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.9 in ./opt/anaconda3/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (8.0.10)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in ./opt/anaconda3/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (0.7.4)\n",
      "Requirement already satisfied: setuptools in ./opt/anaconda3/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (52.0.0.post20210125)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in ./opt/anaconda3/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (2.4.1)\n",
      "Requirement already satisfied: pathy>=0.3.5 in ./opt/anaconda3/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (0.6.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in ./opt/anaconda3/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (4.59.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in ./opt/anaconda3/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (3.0.8)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in ./opt/anaconda3/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (0.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in ./opt/anaconda3/lib/python3.8/site-packages (from packaging>=20.0->spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (2.4.7)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in ./opt/anaconda3/lib/python3.8/site-packages (from pathy>=0.3.5->spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./opt/anaconda3/lib/python3.8/site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (3.7.4.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in ./opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (1.26.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in ./opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in ./opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (4.0.0)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in ./opt/anaconda3/lib/python3.8/site-packages (from typer<0.5.0,>=0.3.0->spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (7.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in ./opt/anaconda3/lib/python3.8/site-packages (from jinja2->spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (1.1.1)\n",
      "Installing collected packages: en-core-web-md\n",
      "Successfully installed en-core-web-md-3.1.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_md')\n"
     ]
    }
   ],
   "source": [
    "###################################### loading all the required libraries ################################################\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from string import punctuation\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set( stopwords.words('english'))\n",
    "from nltk.tokenize import word_tokenize\n",
    "import numpy as np\n",
    "import string\n",
    "from nltk.probability import FreqDist\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import spacy\n",
    "!python -m spacy download en_core_web_md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task A: \n",
    "\n",
    "Extract about 5-6k reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 203
    },
    "id": "UeEHMkBeg18E",
    "outputId": "a0458005-4111-40b5-9274-b2e30c9f47fc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>reviews</th>\n",
       "      <th>rating</th>\n",
       "      <th>cleaned_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Last Buffalo In The Park</td>\n",
       "      <td>AshBlackstone from Florida\\n\\n1.34/5  rDev -70...</td>\n",
       "      <td>4.56</td>\n",
       "      <td>[advocate, high, tried, far, recently, deserve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Black &amp; Wild</td>\n",
       "      <td>lupercmda from North Carolina\\n\\n4.77/5  rDev ...</td>\n",
       "      <td>4.53</td>\n",
       "      <td>[rdev, north, opaque, look, type, definitely, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Supplication</td>\n",
       "      <td>Herbnxplorer from California\\n\\n4.88/5  rDev +...</td>\n",
       "      <td>4.60</td>\n",
       "      <td>[never, opinion, well, tried, pinot, notes, pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fort Point Pale Ale - Mosaic Dry Hopped</td>\n",
       "      <td>AZBeerDude72 from Arizona\\n\\n4.25/5  rDev -5.8...</td>\n",
       "      <td>4.51</td>\n",
       "      <td>[rdev, gold, azbeerdude72, floral, look, refre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DFPF</td>\n",
       "      <td>BeerSamurai34 from Texas\\n\\n4.78/5  rDev +5.5%...</td>\n",
       "      <td>4.53</td>\n",
       "      <td>[rdev, fruity, look, oct, 13, 45, 5, 475, over...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6222</th>\n",
       "      <td>King Julius</td>\n",
       "      <td>Tony210 from New Jersey\\n\\n4.48/5  rDev -5.7%\\...</td>\n",
       "      <td>4.75</td>\n",
       "      <td>[orange, rdev, 41521, rating, tony210, tropica...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6223</th>\n",
       "      <td>Gggreennn!</td>\n",
       "      <td>digboy from New Hampshire\\n\\n4.63/5  rDev +1.3...</td>\n",
       "      <td>4.57</td>\n",
       "      <td>[stays, certainly, stone, well, sweet, blast, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6224</th>\n",
       "      <td>Citra</td>\n",
       "      <td>RaulMondesi from California\\n\\n4.55/5  rDev -1...</td>\n",
       "      <td>4.60</td>\n",
       "      <td>[4th, well, woody, night, hype, luster, jolted...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6225</th>\n",
       "      <td>King Sue - Double Dry-Hopped</td>\n",
       "      <td>DokiDokiLitFam from New Jersey\\n\\n4.45/5  rDev...</td>\n",
       "      <td>4.56</td>\n",
       "      <td>[dokidokilitfam, thats, explodes, well, notes,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6226</th>\n",
       "      <td>Moment Of Clarity</td>\n",
       "      <td>MVotter from New York\\n\\n4.25/5  rDev -6.6%\\nl...</td>\n",
       "      <td>4.55</td>\n",
       "      <td>[rdev, coke, dark, look, york, 1inch, maple, f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6227 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        title  \\\n",
       "0                    Last Buffalo In The Park   \n",
       "1                                Black & Wild   \n",
       "2                                Supplication   \n",
       "3     Fort Point Pale Ale - Mosaic Dry Hopped   \n",
       "4                                        DFPF   \n",
       "...                                       ...   \n",
       "6222                              King Julius   \n",
       "6223                               Gggreennn!   \n",
       "6224                                    Citra   \n",
       "6225             King Sue - Double Dry-Hopped   \n",
       "6226                        Moment Of Clarity   \n",
       "\n",
       "                                                reviews  rating  \\\n",
       "0     AshBlackstone from Florida\\n\\n1.34/5  rDev -70...    4.56   \n",
       "1     lupercmda from North Carolina\\n\\n4.77/5  rDev ...    4.53   \n",
       "2     Herbnxplorer from California\\n\\n4.88/5  rDev +...    4.60   \n",
       "3     AZBeerDude72 from Arizona\\n\\n4.25/5  rDev -5.8...    4.51   \n",
       "4     BeerSamurai34 from Texas\\n\\n4.78/5  rDev +5.5%...    4.53   \n",
       "...                                                 ...     ...   \n",
       "6222  Tony210 from New Jersey\\n\\n4.48/5  rDev -5.7%\\...    4.75   \n",
       "6223  digboy from New Hampshire\\n\\n4.63/5  rDev +1.3...    4.57   \n",
       "6224  RaulMondesi from California\\n\\n4.55/5  rDev -1...    4.60   \n",
       "6225  DokiDokiLitFam from New Jersey\\n\\n4.45/5  rDev...    4.56   \n",
       "6226  MVotter from New York\\n\\n4.25/5  rDev -6.6%\\nl...    4.55   \n",
       "\n",
       "                                         cleaned_review  \n",
       "0     [advocate, high, tried, far, recently, deserve...  \n",
       "1     [rdev, north, opaque, look, type, definitely, ...  \n",
       "2     [never, opinion, well, tried, pinot, notes, pe...  \n",
       "3     [rdev, gold, azbeerdude72, floral, look, refre...  \n",
       "4     [rdev, fruity, look, oct, 13, 45, 5, 475, over...  \n",
       "...                                                 ...  \n",
       "6222  [orange, rdev, 41521, rating, tony210, tropica...  \n",
       "6223  [stays, certainly, stone, well, sweet, blast, ...  \n",
       "6224  [4th, well, woody, night, hype, luster, jolted...  \n",
       "6225  [dokidokilitfam, thats, explodes, well, notes,...  \n",
       "6226  [rdev, coke, dark, look, york, 1inch, maple, f...  \n",
       "\n",
       "[6227 rows x 4 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "################################### loading and cleaning the scraped data ################################################\n",
    "df = pd.read_csv('beer.csv')\n",
    "\n",
    "#removing unnecessary columns \n",
    "df = df.drop(columns=['web-scraper-order','web-scraper-start-url','beer_link-href','title'])\n",
    "\n",
    "#renaming the columns \n",
    "df = df.rename(columns = {'beer_link' : 'title'})\n",
    "\n",
    "#cleaning the reviews\n",
    "\n",
    "###### removing punctuations \n",
    "df['cleaned_review'] = df['reviews'].apply(lambda x :str(x).translate(str.maketrans('', '', string.punctuation)))\n",
    "\n",
    "###### converting the characters to lower case \n",
    "df['cleaned_review'] = df['cleaned_review'].apply(lambda x :x.lower())\n",
    "\n",
    "###### tokenizing the reviews \n",
    "df['cleaned_review'] = df['cleaned_review'].apply(word_tokenize).apply(set).apply(list)\n",
    "\n",
    "###### removing stop words from the reviews token \n",
    "def remove_stopwords(s):\n",
    "    return [w for w in s if not w in stop_words] \n",
    "    \n",
    "df['cleaned_review'] =  df['cleaned_review'].apply(remove_stopwords)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task B: \n",
    "\n",
    "Assume that a customer, who will be using this recommender system, has specified 3 attributes in a product. E.g., one website describes multiple attributes of beer:\n",
    "https://www.dummies.com/food-drink/drinks/beer/beer-for-dummies-cheat-sheet/\n",
    "\n",
    "A word frequency analysis of beer reviews may be a better way to find important attributes. \n",
    "Assume that a customer has specified three attributes of the product as being important to him or her.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "vhk5Wqd1pWdW",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##################################### performing word frequency analysis ################################################\n",
    "#creating bag of words of all the tokens \n",
    "tokens_list = df.cleaned_review.sum()\n",
    "\n",
    "#creating frequency distribution of all the tokens \n",
    "freq = nltk.FreqDist(tokens_list)\n",
    "\n",
    "#identifying top 100 frequently used words \n",
    "top_words = freq.most_common(100)\n",
    "\n",
    "#choosing 3 attributes based on most frequently occuring words \n",
    "attr_list = [\"nose\", \"body\", \"sweet\",'dark','aroma']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('rdev', 6227),\n",
       " ('taste', 6225),\n",
       " ('overall', 6225),\n",
       " ('smell', 6225),\n",
       " ('look', 6224),\n",
       " ('feel', 6224),\n",
       " ('45', 4378),\n",
       " ('head', 3517),\n",
       " ('425', 3061),\n",
       " ('475', 3049),\n",
       " ('beer', 2779),\n",
       " ('4', 1970),\n",
       " ('pours', 1780),\n",
       " ('nose', 1736),\n",
       " ('sweet', 1683),\n",
       " ('one', 1679),\n",
       " ('dark', 1662),\n",
       " ('5', 1650),\n",
       " ('carbonation', 1637),\n",
       " ('like', 1619),\n",
       " ('chocolate', 1608),\n",
       " ('2021', 1537),\n",
       " ('finish', 1526),\n",
       " ('good', 1517),\n",
       " ('mouthfeel', 1506),\n",
       " ('aroma', 1477),\n",
       " ('nice', 1438),\n",
       " ('body', 1434),\n",
       " ('well', 1432),\n",
       " ('2019', 1417),\n",
       " ('bottle', 1412),\n",
       " ('lacing', 1411),\n",
       " ('black', 1394),\n",
       " ('2020', 1351),\n",
       " ('light', 1335),\n",
       " ('notes', 1330),\n",
       " ('vanilla', 1307),\n",
       " ('medium', 1275),\n",
       " ('white', 1248),\n",
       " ('smooth', 1239),\n",
       " ('flavor', 1213),\n",
       " ('bit', 1203),\n",
       " ('glass', 1202),\n",
       " ('bourbon', 1186),\n",
       " ('color', 1175),\n",
       " ('fruit', 1161),\n",
       " ('great', 1160),\n",
       " ('thick', 1152),\n",
       " ('really', 1151),\n",
       " ('poured', 1137),\n",
       " ('2018', 1132),\n",
       " ('coffee', 1107),\n",
       " ('little', 1082),\n",
       " ('orange', 1066),\n",
       " ('flavors', 1050),\n",
       " ('brown', 1007),\n",
       " ('barrel', 989),\n",
       " ('bitterness', 968),\n",
       " ('oak', 962),\n",
       " ('citrus', 955),\n",
       " ('new', 940),\n",
       " ('much', 892),\n",
       " ('sweetness', 879),\n",
       " ('creamy', 862),\n",
       " ('’', 845),\n",
       " ('malt', 830),\n",
       " ('hazy', 823),\n",
       " ('dry', 815),\n",
       " ('2017', 807),\n",
       " ('stout', 790),\n",
       " ('full', 785),\n",
       " ('caramel', 754),\n",
       " ('big', 731),\n",
       " ('balanced', 730),\n",
       " ('still', 700),\n",
       " ('best', 699),\n",
       " ('rich', 688),\n",
       " ('get', 682),\n",
       " ('alcohol', 682),\n",
       " ('bitter', 675),\n",
       " ('may', 671),\n",
       " ('thin', 663),\n",
       " ('almost', 651),\n",
       " ('375', 635),\n",
       " ('smells', 633),\n",
       " ('massachusetts', 633),\n",
       " ('pour', 627),\n",
       " ('slightly', 624),\n",
       " ('palate', 623),\n",
       " ('retention', 616),\n",
       " ('would', 615),\n",
       " ('abv', 607),\n",
       " ('quite', 601),\n",
       " ('bodied', 597),\n",
       " ('grapefruit', 596),\n",
       " ('jan', 595),\n",
       " ('mar', 590),\n",
       " ('tropical', 588),\n",
       " ('finger', 580),\n",
       " ('complex', 571)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task C: \n",
    "\n",
    "Perform a similarity analysis using cosine similarity (without word embeddings) with the 3 attributes specified by the customer and the reviews. From the output file, calculate the average similarity between each product and the preferred attributes. \n",
    "For similarity analysis, use cosine similarity with bag of words. The script should accept as input a file with the product attributes, and calculate similarity scores (between 0 and 1) between these attributes and each review. That is, the output file should have 3 columns – product_name (for each product, the product_name will repeat as many times as there are reviews of the product), product_review and similarity_score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_name</th>\n",
       "      <th>product_review</th>\n",
       "      <th>similarity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Last Buffalo In The Park</td>\n",
       "      <td>AshBlackstone from Florida\\n\\n1.34/5  rDev -70...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Black &amp; Wild</td>\n",
       "      <td>lupercmda from North Carolina\\n\\n4.77/5  rDev ...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Supplication</td>\n",
       "      <td>Herbnxplorer from California\\n\\n4.88/5  rDev +...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fort Point Pale Ale - Mosaic Dry Hopped</td>\n",
       "      <td>AZBeerDude72 from Arizona\\n\\n4.25/5  rDev -5.8...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DFPF</td>\n",
       "      <td>BeerSamurai34 from Texas\\n\\n4.78/5  rDev +5.5%...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6222</th>\n",
       "      <td>King Julius</td>\n",
       "      <td>Tony210 from New Jersey\\n\\n4.48/5  rDev -5.7%\\...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6223</th>\n",
       "      <td>Gggreennn!</td>\n",
       "      <td>digboy from New Hampshire\\n\\n4.63/5  rDev +1.3...</td>\n",
       "      <td>0.073922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6224</th>\n",
       "      <td>Citra</td>\n",
       "      <td>RaulMondesi from California\\n\\n4.55/5  rDev -1...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6225</th>\n",
       "      <td>King Sue - Double Dry-Hopped</td>\n",
       "      <td>DokiDokiLitFam from New Jersey\\n\\n4.45/5  rDev...</td>\n",
       "      <td>0.049875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6226</th>\n",
       "      <td>Moment Of Clarity</td>\n",
       "      <td>MVotter from New York\\n\\n4.25/5  rDev -6.6%\\nl...</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6227 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 product_name  \\\n",
       "0                    Last Buffalo In The Park   \n",
       "1                                Black & Wild   \n",
       "2                                Supplication   \n",
       "3     Fort Point Pale Ale - Mosaic Dry Hopped   \n",
       "4                                        DFPF   \n",
       "...                                       ...   \n",
       "6222                              King Julius   \n",
       "6223                               Gggreennn!   \n",
       "6224                                    Citra   \n",
       "6225             King Sue - Double Dry-Hopped   \n",
       "6226                        Moment Of Clarity   \n",
       "\n",
       "                                         product_review  similarity_score  \n",
       "0     AshBlackstone from Florida\\n\\n1.34/5  rDev -70...          0.000000  \n",
       "1     lupercmda from North Carolina\\n\\n4.77/5  rDev ...          0.000000  \n",
       "2     Herbnxplorer from California\\n\\n4.88/5  rDev +...          0.000000  \n",
       "3     AZBeerDude72 from Arizona\\n\\n4.25/5  rDev -5.8...          0.000000  \n",
       "4     BeerSamurai34 from Texas\\n\\n4.78/5  rDev +5.5%...          0.000000  \n",
       "...                                                 ...               ...  \n",
       "6222  Tony210 from New Jersey\\n\\n4.48/5  rDev -5.7%\\...          0.000000  \n",
       "6223  digboy from New Hampshire\\n\\n4.63/5  rDev +1.3...          0.073922  \n",
       "6224  RaulMondesi from California\\n\\n4.55/5  rDev -1...          0.000000  \n",
       "6225  DokiDokiLitFam from New Jersey\\n\\n4.45/5  rDev...          0.049875  \n",
       "6226  MVotter from New York\\n\\n4.25/5  rDev -6.6%\\nl...          0.083333  \n",
       "\n",
       "[6227 rows x 3 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############################### calculating cosine similarity based on bag of words ################################################\n",
    "attribute = \", \".join(attr_list)\n",
    "\n",
    "#defining a function to calculate cosine similarity between attributes and reviews \n",
    "def similarity(list_of_words):\n",
    "    string = \", \".join(list_of_words)\n",
    "    documents = [attribute, string]\n",
    "    count_vectorizer = CountVectorizer()\n",
    "    count_matrix = count_vectorizer.fit_transform(documents)\n",
    "    return cosine_similarity(count_matrix[0:1],count_matrix)[0,1]\n",
    "\n",
    "#calculating the similarity score\n",
    "df[\"similarity\"] = df[\"cleaned_review\"].map(similarity)\n",
    "df_task_c = df[['product_name', 'reviews','similarity']]\n",
    "df_task_c  = df_task_c.rename(columns = {'title' : 'product_name', 'reviews' : 'product_review', 'similarity' : 'similarity_score'})\n",
    "df_task_c\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N_7go1iJq3W8",
    "outputId": "327089a3-b0a0-45e9-fa69-6f6830451335"
   },
   "source": [
    "## Task D: \n",
    "\n",
    "For every review, perform a sentiment analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "p25noPapqs50"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>reviews</th>\n",
       "      <th>rating</th>\n",
       "      <th>cleaned_review</th>\n",
       "      <th>similarity</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Last Buffalo In The Park</td>\n",
       "      <td>AshBlackstone from Florida\\n\\n1.34/5  rDev -70...</td>\n",
       "      <td>4.56</td>\n",
       "      <td>[advocate, high, tried, far, recently, deserve...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.4588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Black &amp; Wild</td>\n",
       "      <td>lupercmda from North Carolina\\n\\n4.77/5  rDev ...</td>\n",
       "      <td>4.53</td>\n",
       "      <td>[rdev, north, opaque, look, type, definitely, ...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.8795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Supplication</td>\n",
       "      <td>Herbnxplorer from California\\n\\n4.88/5  rDev +...</td>\n",
       "      <td>4.60</td>\n",
       "      <td>[never, opinion, well, tried, pinot, notes, pe...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.9957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fort Point Pale Ale - Mosaic Dry Hopped</td>\n",
       "      <td>AZBeerDude72 from Arizona\\n\\n4.25/5  rDev -5.8...</td>\n",
       "      <td>4.51</td>\n",
       "      <td>[rdev, gold, azbeerdude72, floral, look, refre...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.8725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DFPF</td>\n",
       "      <td>BeerSamurai34 from Texas\\n\\n4.78/5  rDev +5.5%...</td>\n",
       "      <td>4.53</td>\n",
       "      <td>[rdev, fruity, look, oct, 13, 45, 5, 475, over...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.8020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6222</th>\n",
       "      <td>King Julius</td>\n",
       "      <td>Tony210 from New Jersey\\n\\n4.48/5  rDev -5.7%\\...</td>\n",
       "      <td>4.75</td>\n",
       "      <td>[orange, rdev, 41521, rating, tony210, tropica...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.9274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6223</th>\n",
       "      <td>Gggreennn!</td>\n",
       "      <td>digboy from New Hampshire\\n\\n4.63/5  rDev +1.3...</td>\n",
       "      <td>4.57</td>\n",
       "      <td>[stays, certainly, stone, well, sweet, blast, ...</td>\n",
       "      <td>0.073922</td>\n",
       "      <td>0.9063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6224</th>\n",
       "      <td>Citra</td>\n",
       "      <td>RaulMondesi from California\\n\\n4.55/5  rDev -1...</td>\n",
       "      <td>4.60</td>\n",
       "      <td>[4th, well, woody, night, hype, luster, jolted...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.7496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6225</th>\n",
       "      <td>King Sue - Double Dry-Hopped</td>\n",
       "      <td>DokiDokiLitFam from New Jersey\\n\\n4.45/5  rDev...</td>\n",
       "      <td>4.56</td>\n",
       "      <td>[dokidokilitfam, thats, explodes, well, notes,...</td>\n",
       "      <td>0.049875</td>\n",
       "      <td>0.9841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6226</th>\n",
       "      <td>Moment Of Clarity</td>\n",
       "      <td>MVotter from New York\\n\\n4.25/5  rDev -6.6%\\nl...</td>\n",
       "      <td>4.55</td>\n",
       "      <td>[rdev, coke, dark, look, york, 1inch, maple, f...</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.8822</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6227 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        title  \\\n",
       "0                    Last Buffalo In The Park   \n",
       "1                                Black & Wild   \n",
       "2                                Supplication   \n",
       "3     Fort Point Pale Ale - Mosaic Dry Hopped   \n",
       "4                                        DFPF   \n",
       "...                                       ...   \n",
       "6222                              King Julius   \n",
       "6223                               Gggreennn!   \n",
       "6224                                    Citra   \n",
       "6225             King Sue - Double Dry-Hopped   \n",
       "6226                        Moment Of Clarity   \n",
       "\n",
       "                                                reviews  rating  \\\n",
       "0     AshBlackstone from Florida\\n\\n1.34/5  rDev -70...    4.56   \n",
       "1     lupercmda from North Carolina\\n\\n4.77/5  rDev ...    4.53   \n",
       "2     Herbnxplorer from California\\n\\n4.88/5  rDev +...    4.60   \n",
       "3     AZBeerDude72 from Arizona\\n\\n4.25/5  rDev -5.8...    4.51   \n",
       "4     BeerSamurai34 from Texas\\n\\n4.78/5  rDev +5.5%...    4.53   \n",
       "...                                                 ...     ...   \n",
       "6222  Tony210 from New Jersey\\n\\n4.48/5  rDev -5.7%\\...    4.75   \n",
       "6223  digboy from New Hampshire\\n\\n4.63/5  rDev +1.3...    4.57   \n",
       "6224  RaulMondesi from California\\n\\n4.55/5  rDev -1...    4.60   \n",
       "6225  DokiDokiLitFam from New Jersey\\n\\n4.45/5  rDev...    4.56   \n",
       "6226  MVotter from New York\\n\\n4.25/5  rDev -6.6%\\nl...    4.55   \n",
       "\n",
       "                                         cleaned_review  similarity  sentiment  \n",
       "0     [advocate, high, tried, far, recently, deserve...    0.000000     0.4588  \n",
       "1     [rdev, north, opaque, look, type, definitely, ...    0.000000     0.8795  \n",
       "2     [never, opinion, well, tried, pinot, notes, pe...    0.000000     0.9957  \n",
       "3     [rdev, gold, azbeerdude72, floral, look, refre...    0.000000     0.8725  \n",
       "4     [rdev, fruity, look, oct, 13, 45, 5, 475, over...    0.000000     0.8020  \n",
       "...                                                 ...         ...        ...  \n",
       "6222  [orange, rdev, 41521, rating, tony210, tropica...    0.000000     0.9274  \n",
       "6223  [stays, certainly, stone, well, sweet, blast, ...    0.073922     0.9063  \n",
       "6224  [4th, well, woody, night, hype, luster, jolted...    0.000000     0.7496  \n",
       "6225  [dokidokilitfam, thats, explodes, well, notes,...    0.049875     0.9841  \n",
       "6226  [rdev, coke, dark, look, york, 1inch, maple, f...    0.083333     0.8822  \n",
       "\n",
       "[6227 rows x 6 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############################### calculating sentiment score of each review ################################################\n",
    "analyser = SentimentIntensityAnalyzer()\n",
    "\n",
    "#defining a function to calculate the sentiment score\n",
    "def sentiment_analyzer_scores(sentence):\n",
    "    \"\"\"Generate seniment score\"\"\"\n",
    "    scores = analyser.polarity_scores(sentence)\n",
    "    return scores['compound']\n",
    "\n",
    "df['sentiment'] = df['reviews'].map(sentiment_analyzer_scores)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task E: \n",
    "\n",
    "Assume an evaluation score for each beer = average similarity score + average sentiment score. \n",
    "Now recommend 3 products to the customer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 172
    },
    "id": "4T8vXjTPvKQr",
    "outputId": "71100c74-93bd-4e4a-989f-a840588faeca"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>similarity</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>recommend</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Expedition Stout - Bourbon Barrel-Aged</th>\n",
       "      <td>0.083112</td>\n",
       "      <td>0.899836</td>\n",
       "      <td>0.982948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mother Of All Storms</th>\n",
       "      <td>0.067683</td>\n",
       "      <td>0.903976</td>\n",
       "      <td>0.971659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Genealogy Of Morals - Bourbon Barrel-Aged</th>\n",
       "      <td>0.065885</td>\n",
       "      <td>0.904744</td>\n",
       "      <td>0.970629</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           similarity  sentiment  recommend\n",
       "title                                                                      \n",
       "Expedition Stout - Bourbon Barrel-Aged       0.083112   0.899836   0.982948\n",
       "Mother Of All Storms                         0.067683   0.903976   0.971659\n",
       "Genealogy Of Morals - Bourbon Barrel-Aged    0.065885   0.904744   0.970629"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############################ providing beer recommendation based on cosine similarity ################################################\n",
    "combined_reviews_cosine = df.groupby('title')[['similarity','sentiment']].mean()\n",
    "combined_reviews_cosine['recommend'] = combined_reviews_cosine['similarity']+combined_reviews_cosine['sentiment']\n",
    "recommended_cosine = combined_reviews_cosine.sort_values(by='recommend', ascending=False)[0:3]\n",
    "recommended_cosine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task F: \n",
    "\n",
    "How would your recommendation change if you use word vectors (the spaCy package would be the easiest to use with pretrained word vectors) instead of plain vanilla bag-of-words cosine similarity? One way to analyze the difference would be to consider the % of reviews that mention a preferred attribute. E.g., if you recommend a product, what % of its reviews mention an attribute specified by the customer? Do you see any difference across bag-of-words and word vector approaches? This article may be useful: https://medium.com/swlh/word-embeddings-versus-bag-of-words-the-curious-case-of-recommender-systems-6ac1604d4424?source=friends_link&sk=d746da9f094d1222a35519387afc6338\n",
    "Note that the article doesn’t claim that bag-of-words will always be better than word embeddings for recommender systems. It lays out conditions under which it is likely to be the case. That is, depending on the attributes you use, you may or may not see the same effect. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'combined_reviews' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-d7b0dd674e38>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# providing the beer recommendation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mcombined_reviews_spacy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'title'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'spacy_similarity'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'sentiment'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mcombined_reviews_spacy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'recommend'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcombined_reviews_spacy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'spacy_similarity'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mcombined_reviews\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sentiment'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0mrecommended_spacy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcombined_reviews_spacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'recommend'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mrecommended_spacy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'combined_reviews' is not defined"
     ]
    }
   ],
   "source": [
    "############################ providing beer recommendation based on spacy ################################################\n",
    "\n",
    "#calculating similarity score based on spacy \n",
    "nlp = spacy.load('en_core_web_md')\n",
    "\n",
    "#defining a function to calculate spacy similarity \n",
    "def spacy_similarity(list_of_words):\n",
    "    doc1 = nlp(list_of_words)\n",
    "    doc2 = nlp(' '.join(attr_list))\n",
    "    return doc1.similarity(doc2)\n",
    "\n",
    "#calculating spacy similarity \n",
    "df['spacy_similarity'] = df['reviews'].apply(spacy_similarity)\n",
    "\n",
    "# providing the beer recommendation \n",
    "combined_reviews_spacy = df.groupby('title')[['spacy_similarity','sentiment']].mean()\n",
    "combined_reviews_spacy['recommend'] = combined_reviews_spacy['spacy_similarity']+combined_reviews['sentiment']\n",
    "recommended_spacy = combined_reviews_spacy.sort_values(by='recommend', ascending=False)[0:3]\n",
    "recommended_spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################ analysing the differences between the recommendations ################################################\n",
    "\n",
    "# defining function to check if attribute is present in review \n",
    "def review_attr1(review):\n",
    "    if attr_list[0] in review:\n",
    "        return 1 \n",
    "    else:\n",
    "        return 0;\n",
    "\n",
    "def review_attr2(review):\n",
    "    if attr_list[1] in review:\n",
    "        return 1 \n",
    "    else:\n",
    "        return 0;\n",
    "\n",
    "def review_attr3(review):\n",
    "    if attr_list[2] in review:\n",
    "        return 1 \n",
    "    else:\n",
    "        return 0;\n",
    "\n",
    "# creating columns identifying if attributes are present in review \n",
    "df['attribute_presence_1'] = df['reviews'].apply(review_attr1)\n",
    "df['attribute_presence_2'] = df['reviews'].apply(review_attr2)\n",
    "df['attribute_presence_3'] = df['reviews'].apply(review_attr3)\n",
    "\n",
    "# aggregating the attribute presence across beers\n",
    "combined_reviews_cosine = df.groupby('title')[['similarity','sentiment',]].mean()\n",
    "combined_reviews_cosine['recommend'] = combined_reviews_cosine['similarity']+combined_reviews['sentiment']\n",
    "df_aggregated = df.groupby('title')[['attribute_presence_1','attribute_presence_2','attribute_presence_3']].sum()\n",
    "df_aggregated\n",
    "\n",
    "# % cosine recommended beer reviews containing the attribute words \n",
    "recommended_cosine = recommended_cosine.merge(df_aggregated, left_index = True, right_index = True)\n",
    "# recommended_cosine['attribute_presence_1'] = recommended_cosine['attribute_presence_1']/25\n",
    "# recommended_cosine['attribute_presence_2'] = recommended_cosine['attribute_presence_2']/25\n",
    "# recommended_cosine['attribute_presence_3'] = recommended_cosine['attribute_presence_3']/25\n",
    "recommended_cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# % spacy recommended beer reviews containing the attribute words \n",
    "recommended_spacy = recommended_spacy.merge(df_aggregated, left_index = True, right_index = True)\n",
    "# recommended_spacy['attribute_presence_1'] = recommended_spacy['attribute_presence_1']/25\n",
    "# recommended_spacy['attribute_presence_2'] = recommended_spacy['attribute_presence_2']/25\n",
    "# recommended_spacy['attribute_presence_3'] = recommended_spacy['attribute_presence_3']/25\n",
    "recommended_spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that 2 out 3 beer recommendations are similar based on both cosine and spacy similarity. The 3rd beer recommended based on cosine similarity (Expedition Stout - Bourbon Barrel-Aged) has lot more attribute mentions (17,5,2 for each attribute respectively) than the 3rd beer recomendation based on spacy similarity (Cable Car Kriek) has fewer mentions (2,4,3 for each attribute respectively). Spacy must be looking at words similar to the attributes and hence providing the increased similarity. Hence, lets look at the frequently occuring words across reviews for Cable Car Kriek and see what words might be similar to the attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "############################## identifying spacy similar words to the attributes ################################################\n",
    "#creating bag of words of all the tokens across the reviews\n",
    "tokens_list = df[df['title'] == 'Cable Car Kriek']['cleaned_review'].sum()\n",
    "\n",
    "#identifying the spacy similar words \n",
    "for i in attr_list:\n",
    "    print ('\\033[1m' + 'Spacy similar words to {}'.format(i) + '\\033[0m')\n",
    "    ms = nlp.vocab.vectors.most_similar(np.asarray([nlp.vocab.vectors[nlp.vocab.strings[i]]]), n=30)\n",
    "    words = [nlp.vocab.strings[w] for w in ms[0][0]]\n",
    "    distances = ms[2]\n",
    "    for x in words:\n",
    "        if x in tokens_list:\n",
    "            print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that spacy is assessing the similarity based on a lot more words and hence the increased similarity. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task G: \n",
    "\n",
    "How would your recommendations differ if you ignored the similarity and feature sentiment scores and simply chose the 3 highest rated products from your entire dataset? Would these products meet the requirements of the user looking for recommendations? Why or why not? Justify your answer with analysis. Use the similarity and sentiment scores as well as overall ratings to answer this question. \n",
    "Here is a sample web implementation of a recommender system based on the same principles (runningshoe4you.com), but in this assignment, we will not have the time for this type of full automation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################## identifying top 3 beers based on rating ################################################\n",
    "recommended_rating = df.groupby('title')[['rating','similarity','spacy_similarity','sentiment']].mean().sort_values(by = 'rating', ascending = False)[:3]\n",
    "recommended_rating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since, the recommendation are simply based on the ratings, they might not necessarily be based on the attributes. We can also infer this from the low cosine and spacy similarity scores. Lets look at the most frequently occuring attributes across the reviews of these 3 beers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################### performing word frequency analysis ################################################\n",
    "#creating bag of words of all the tokens \n",
    "tokens_list = df.merge(recommended_rating, left_on = 'title', right_index = True).cleaned_review.sum()\n",
    "\n",
    "#creating frequency distribution of all the tokens \n",
    "freq = nltk.FreqDist(tokens_list)\n",
    "\n",
    "#identifying top 100 frequently used words \n",
    "top_words = freq.most_common(100)\n",
    "top_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How would your recommendations differ if you ignored the similarity and feature sentiment scores and simply chose the 3 highest rated products from your entire dataset? Would these products meet the requirements of the user looking for recommendations? Why or why not? Justify your answer with analysis. Use the similarity and sentiment scores as well as overall ratings to answer this question. \n",
    "\n",
    "Our reccomendations would differ if we ignored the similarity and feature sentiment scores and simply chose the 3 highest rated products then I our reccomendations would be based off entirely different beers. The three highest rated beers did not sentiments that fit into our reccomendations because our sentiment analysis was based off the sentiment in the written reviews by users. The ratings are a numerical scale that may not correspond with the sentiment written in the reviews. These products would not meet the requirements of the user looking for reccomendations because the 3 highest rated beers do not have the attributes we chose in our reccomendation. This is due to the sentiment not being high for these attributes for the 3 highest rated beers. "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Homework 2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
