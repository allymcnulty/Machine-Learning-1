{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "evHVxwk2JA-3"
   },
   "source": [
    "# <p style=\"text-align: center;\">MIS 382N: Advanced Machine Learning</p>\n",
    "# <p style=\"text-align: center;\">Homework 1</p>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TWWU_gOSLEEv"
   },
   "source": [
    "# Question 1: MLOps (10 pts)\n",
    "Read this [article](https://towardsdatascience.com/what-is-mlops-everything-you-must-know-to-get-started-523f2d0b8bd8) \"What is MLOps — Everything You Must Know to Get Started\", which gives a quick walkthrough of the machine learning development lifecycle and explains how MLOps come into play, or watch this [video](https://www.youtube.com/watch?v=06-AZXmwHjo) which you may find interesting.\n",
    "\n",
    "1. (**4 pts**) Use your own words to describe what MLOps is, and what challenges MLOps address. Limit your answer to one paragraph.\n",
    "\n",
    "2. (**6 pts**) Describe what the main phases in MLOps are. Your answer should be 2-3 paragraphs.\n",
    "\n",
    "\n",
    "## Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Use your own words to describe what MLOps is, and what challenges MLOps address. Limit your answer to one paragraph.\n",
    "\n",
    "MLOPs stands for Machine Learning Operations and it is an engineering field that works to bring together machine learning system development and deployment. The goal is to standardize the constant delivery of high performing machine learning models. Several teams are involved with MLOps including the product, data engineering, data science, and IT teams. MLOps faces many challenges including a shortage of human capital, ML processes not being able to adapt to changing business needs due to dependencies in the processes, technical and businesss teams not communicating effectively, and the difficulty of assessing the risk associated with applying ML systems. \n",
    "\n",
    "2. Describe what the main phases in MLOps are. Your answer should be 2-3 paragraphs.\n",
    "MLOps is made up of 7 main phases. These phases include: Framing ML problems from business objectives, Architect ML and data solutions for the problem, data preperation and processing,model training and experimentation, building and automating ML pipelines, deploying models to the production system, and monitor, optimize, and maintain models. \n",
    "\n",
    "The first phase Framing ML problems from business objectives includes defining the problem or goal that the ML model is aiming to address/meet. These objectives include performance measures,technical requirements,budget, and general KPIs that will guide the monitoring process after the models are deployed. The next phase Architect ML and data solutions for the problem includes searching for input data and models that are appropriate for the data. The data preperation and processing model is part of the data engineering process and includes feature engineering, cleaning, and selecting the set of features that will affect the output of the problem the model is trying to solve. The next phase Model training and experimentation includes training the ML model and running several different types of models to see which model is best suited for the data and business goal. This step also includes testing the model, checking the model against baselines, and scaling the model. The fifth step Building and Automating ML Pipelines includes identifying system requirements, choosing a hybrid or multi-cloud cloud architecture, building training and testing pipelines, tracking and auditing the pipeline runs, and finally performing data validation. The sixth step Deploying Models to the Production System includes either using a static deployment or a dynamic deployment. A static deployment packages the model into installable application software and them deploys it. Dynamic deployment deploys the model using a web framework and is offered as an API endpoint to user requests.Finally the the last step Monitor, Optimize, and Maintain models includes ensuring that the entire model remains in production. This is accomplished by keeping track of performance and quality of model predictions, establishing logging strategies and evaluation metrics, troubleshooting failures and biases in the system, and tuning the model performance in training and serving pipelines that were deployed in production. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wusA9L1LmUMH"
   },
   "source": [
    "# Question 2: Applications of Machine Learning (5 pts)\n",
    "Read this [article](https://builtin.com/data-science/data-science-applications-examples) \"17 Data Science Applications & Examples\" and pick one of the data science systems used by various organizations according to this blog. \n",
    "\n",
    "For this system you have chosen, answer the following questions. Please limit your answer to one paragraph:\n",
    "\n",
    "1. What kind of machine learning problem is involved (e.g. classification, regression, clustering, outlier detection,...) in this system?\n",
    "2. Speculate on what kind of data may be needed and how the results can be useful to the organization.\n",
    "3. What do you think are the ethical implications of using machine learning in a domain like this?\n",
    "\n",
    "## Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. What kind of machine learning problem is involved (e.g. classification, regression, clustering, outlier detection,...) in this system?\n",
    "\n",
    "The machine learning problem for the Streetlight Data involves identifying traffic patterns for cars, bikes, and pedestrians on the roads. This system seems to use a clustering model to group the various travelers and understand their movement. By clustering these groups of people, the system can further identify high traffic areas by the types of commuters and make predictions for traffic, alternate routes, streetlight frequencies and many other factors involved in city planning. \n",
    "\n",
    "2. Speculate on what kind of data may be needed and how the results can be useful to the organization.\n",
    "\n",
    "Some of the data that would be important is the number of commuters at any given hour of the day, regions of high traffic, mode of transportation for commuters, popular modes of travel in regions. This data is important for the system to be able to understand commuter patterns and identify priorities in city plans such as potential bus routes, street lights, and road condition maintenance.\n",
    "\n",
    "3. What do you think are the ethical implications of using machine learning in a domain like this?\n",
    "\n",
    "The ethical implications is that all data from phones and GPS systems is being taken advantage of by the company to build these systems. This is an invasion of privacy since it is essentially tracking where people are at every moment of the day. This data could easily be misused to stalk people and potentially put people in dangerous situations. Moreover, many people are most likely not aware that their data from their GPS devices is being used for such activity. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2w8za9lLmVO7"
   },
   "source": [
    "# Question 3: Simpson's Paradox (10 pts)\n",
    "A data scientist should be careful about drawing unwarranted conclusions about any data that is presented. One of the 'gotchas' that can happen even in apparently very simple tabular summaries, is called Simpson's paradox.\n",
    "\n",
    "Read this [article](https://www.covid-datascience.com/post/israeli-data-how-can-efficacy-vs-severe-disease-be-strong-when-60-of-hospitalized-are-vaccinated), which explains why the computed efficacy of the Pfizer vaccine is misleadingly low (67.5%) when you lump all people together, but once you stratify people by age (which is the right thing to do), you get much higher efficacy numbers.\n",
    "\n",
    "1.(**5 pts**) Explain in your own words what Simpson's paradox is, and how this 'paradox' can happen in real data.\n",
    "\n",
    "2.(**5 pts**) Find and mention another example of Simpson's paradox (but not any of the 3 examples given in the Wikipedia entry for 'Simpson's paradox'), state why the paradox appeared in your chosen example. Also give a reference (URL) to your source for the chosen example.\n",
    "\n",
    "## Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Explain in your own words what Simpson's paradox is, and how this 'paradox' can happen in real data.\n",
    "\n",
    "Simpson's paradox is a phenomenon that can occur when confounding factors in an observational data set lead to misleading results when the data is interpreted as a whole without any stratfication or analysis of the effect of these confounding factors. \n",
    "\n",
    "2. Find and mention another example of Simpson's paradox (but not any of the 3 examples given in the Wikipedia entry for 'Simpson's paradox'), state why the paradox appeared in your chosen example. Also give a reference (URL) to your source for the chosen example.\n",
    "\n",
    "Another example of Simpson's paradox is present in the study of the math results from the National Assessment of Education Progress (NAEP) over two decades from 1992 to 2012. The NAEP administered the only nationally representative exam measuring student learning from 1992 to 2012 and found that math scores did not increase for all 17-year olds between 1992 and 2012. This could lead researchers to conclude that 17 year olds were not learning anymore math in 2012 then they were in 1992. However, when the data is stratfied to break down by race between white students, black students, and Hispanic students, it showed that the average test scores rose for all of these groups between 1992 to 2012. The confounding factor to data is how the composition of students changed over the two decades. In 1992, 75 percent of the students were white, 15 percent were black, and 7 percent were Hispanic. By 2012, 57 percent were white, 13 percent were black, and 22 percent were Hispanic. The increase in progress for each group is not visible in the overall results because the black and Hispanic students had lower average scores. This is why the paradox appeared in this example. \n",
    "\n",
    "URL: https://www.brookings.edu/blog/social-mobility-memos/2015/07/29/when-average-isnt-good-enough-simpsons-paradox-in-education-and-earnings/\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gth0D8jiMBSe"
   },
   "source": [
    "# Question 4: Ridge and Lasso Regression (30 pts)\n",
    "\n",
    "Download the dataset **Admission.csv** from Canvas and use the following codes to import the Admission dataset in Python. \n",
    "\n",
    "There are 7 features in the dataset:\n",
    "\n",
    "1. GRE score\n",
    "2. TOEFL score\n",
    "3. University Rating\n",
    "4. SOP(Statement of Purpose)\n",
    "5. LOR(Letter of Recommendation)\n",
    "6. CGPA\n",
    "7. Research\n",
    "\n",
    "And the target is **Chance of Admission**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "QFazlpLgGpAa"
   },
   "outputs": [],
   "source": [
    "# # Only use this code block if you are using Google Colab.\n",
    "# # If you are using Jupyter Notebook, please ignore this code block. You can directly upload the file to your Jupyter Notebook file systems.\n",
    "# from google.colab import files\n",
    "\n",
    "# ## It will prompt you to select a local file. Click on “Choose Files” then select and upload the file. \n",
    "# ## Wait for the file to be 100% uploaded. You should see the name of the file once Colab has uploaded it.\n",
    "# uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "xsPaOOehGuU6"
   },
   "outputs": [],
   "source": [
    "# Codes below will work for both Google Colab and Jupyter Notebook.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "## Load the dataset into pandas DataFrame\n",
    "df = pd.read_csv('Admission.csv', index_col=0)\n",
    "df = df.replace([np.inf, -np.inf], np.nan) # \n",
    "df = df.fillna(0) # Replace all the NaN values with 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "PmMz72U6Gv-z"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['GRE_Score', 'TOEFL_Score', 'University_Rating', 'SOP', 'LOR ', 'CGPA',\n",
       "       'Research', 'Chance_of_Admit'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns # Show you all the columns in this file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "CyZN-yFfGxlt"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE_Score</th>\n",
       "      <th>TOEFL_Score</th>\n",
       "      <th>University_Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance_of_Admit</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Serial No.</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            GRE_Score  TOEFL_Score  University_Rating  SOP  LOR   CGPA  \\\n",
       "Serial No.                                                               \n",
       "1                 337          118                  4  4.5   4.5  9.65   \n",
       "2                 324          107                  4  4.0   4.5  8.87   \n",
       "3                 316          104                  3  3.0   3.5  8.00   \n",
       "4                 322          110                  3  3.5   2.5  8.67   \n",
       "5                 314          103                  2  2.0   3.0  8.21   \n",
       "\n",
       "            Research  Chance_of_Admit  \n",
       "Serial No.                             \n",
       "1                  1             0.92  \n",
       "2                  1             0.76  \n",
       "3                  1             0.72  \n",
       "4                  1             0.80  \n",
       "5                  0             0.65  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head() # Show you the first 5 rows in this file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "S3TfR0i4G2rO"
   },
   "outputs": [],
   "source": [
    "y = df['Chance_of_Admit'] # The column named Chance_of_Admit is used as the target, and we store it in y\n",
    "X = df.drop(['Chance_of_Admit'], axis=1) # We keep the remaining columns as the features, and store them in x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pKq1KERxJw9y"
   },
   "source": [
    "1)(**2 pts**) Split the data into a training set(75% of data) and a test set(25% of data), using the [train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) function with random_state = 50. Then scale the data (not including target) so that each of the independent variables would have zero mean and unit variance. You can use the [sklearn.preprocessing.scale](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.scale.html) function for this. Print the first 5 rows of the training set after scaling.\n",
    "\n",
    "2)(**5 pts**) Use [sklearn.linear_model.Lasso](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html) and [sklearn.linear_model.Ridge](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html) classes to do a **5-fold** cross validation using sklearn's KFold. For the sweep of the regularization parameter, we will look at a grid of values ranging from α=10^10 to α=10^−6. In Python, you can consider this range of values as follows: alpha = 10**numpy.linspace(6,-6,100) \n",
    "so that you can generate 100 uniform values between -6 to 6 as power series.\n",
    "\n",
    "Fit the 2 regression models with scaled data and report the best chosen **α** based on cross validation as well as the corresponding scoring metric. The cross validation should happen on your training data using **MSE** as the scoring metric.\n",
    "\n",
    "3)(**5 pts**) Run ridge and lasso regression for all of the **α** specified above (on training data), and plot the coefficients learned for each of them - there should be one plot each for lasso and ridge, so a total of two plots; different features' weights of each model should be on the same plot with different colors (3pts). \n",
    "\n",
    "What do you qualitatively observe when the value of the regularization parameter changes (2pts)? \n",
    "\n",
    "4)(**3 pts**) Take the exponential of Y_train as the target, and fit the 2 regression models again. Report the best chosen **α** based on cross validation as well as the corresponding scoring metric. Compare the results of using the original target with the results of using the exponential of the target. What do you observe? \n",
    "\n",
    "5)(**5 pts**) Similarly, use [sklearn.linear_model.ElasticNet](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ElasticNet.html) to do linear regression with different **α** values, and plot the coefficients learned for each of them (2pts). Observe the plot, then explain the pros and cons of ridge, lasso and Elastic Net models (3pts).\n",
    "\n",
    "\n",
    "6)(**5 pts**) Run the following three regression models with **MSE** loss on the training data: \n",
    "\n",
    "a. linear regression without regularization (1pts)\n",
    "\n",
    "b. linear regression with ridge regularization (2pts)\n",
    "\n",
    "c. linear regression with lasso regularization (2pts)\n",
    "\n",
    "For part (b) and (c), use only the best regularization parameters. Report the MSE and R<sup>2</sup> on the test data for each model.\n",
    "\n",
    "7)(**5 pts**) Train the 3 models and report the metrics with the original data without scaling (3pts). \n",
    "\n",
    "Why do we need to scale the data before regularization (2pts)? \n",
    "\n",
    "## Answer:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.52725374,  2.0917706 ,  1.61594354,  0.63150829,  1.72829095,\n",
       "         2.11370277,  0.90453403],\n",
       "       [ 0.74180896,  0.46308859, -0.9310778 , -0.35266047, -1.04140609,\n",
       "         0.29488827,  0.90453403],\n",
       "       [ 0.56726568,  0.13735218,  1.61594354,  0.63150829,  0.62041214,\n",
       "         0.26211684,  0.90453403],\n",
       "       [-0.39272239, -0.51412062, -0.08207069,  0.13942391,  0.62041214,\n",
       "        -0.80295471, -1.1055416 ],\n",
       "       [ 0.47999403,  0.78882499,  0.76693642,  1.12359267,  1.17435154,\n",
       "         1.11417408,  0.90453403]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.25, random_state=50)\n",
    "X_test = scale(X_test, axis=0, with_mean=True, with_std=True, copy=True)\n",
    "X_train = scale(X_train, axis=0, with_mean=True, with_std=True, copy=True)\n",
    "X_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "n_splits = 5\n",
    "kf = KFold(n_splits=n_splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso - Best Alpha: 0.001072267222010321\n",
      "Lasso - Min MSE: 0.004098425318055381\n"
     ]
    }
   ],
   "source": [
    "###Part 2 Lasso Regression\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "alphas = 10**np.linspace(6,-6,100)\n",
    "lasso_dict = {}\n",
    "\n",
    "for a in alphas:\n",
    "    alpha_list = []\n",
    "    for train_index, test_index in kf.split(X_train):\n",
    "        x_train, x_test = X_train[train_index], X_train[test_index]\n",
    "        y_train, y_test = Y_train.iloc[train_index], Y_train.iloc[test_index]\n",
    "    \n",
    "        clf = linear_model.Lasso(random_state=50, max_iter=10000, alpha = a)\n",
    "        clf = clf.fit(x_train, y_train)\n",
    "\n",
    "        mse = mean_squared_error(y_test, clf.predict(x_test))\n",
    "        alpha_list.append(mse)\n",
    "    avg = sum(alpha_list) / len(alpha_list)\n",
    "    lasso_dict[a]= avg\n",
    "\n",
    "best_key_lasso = min(lasso_dict, key=lasso_dict.get)\n",
    "print(\"Lasso - Best Alpha:\", best_key_lasso)\n",
    "print(\"Lasso - Min MSE:\", min(lasso_dict.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge - Best Alpha: 4.641588833612772\n",
      "Ridge - Min MSE: 0.00411801388424071\n"
     ]
    }
   ],
   "source": [
    "###Part 2 Ridge Regression\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "alphas = 10**np.linspace(6,-6,100)\n",
    "ridge_dict = {}\n",
    "\n",
    "for a in alphas:\n",
    "    alpha_list = []\n",
    "    for train_index, test_index in kf.split(X_train):\n",
    "        x_train, x_test = X_train[train_index], X_train[test_index]\n",
    "        y_train, y_test = Y_train.iloc[train_index], Y_train.iloc[test_index]\n",
    "\n",
    "        clf = linear_model.Ridge(random_state=50, max_iter=10000, alpha = a)\n",
    "        clf = clf.fit(x_train, y_train)\n",
    "\n",
    "        mse = mean_squared_error(y_test, clf.predict(x_test))\n",
    "        alpha_list.append(mse)\n",
    "    avg = sum(alpha_list) / len(alpha_list)\n",
    "    ridge_dict[a]= avg\n",
    "\n",
    "best_key_ridge = min(ridge_dict, key=ridge_dict.get)\n",
    "print('Ridge - Best Alpha:', best_key_ridge)\n",
    "print('Ridge - Min MSE:', min(ridge_dict.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Regression Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Part 3 Ridge Plot\n",
    "import matplotlib.pyplot as plt\n",
    "coef = []\n",
    "for a in alphas:\n",
    "    ridge = linear_model.Ridge(alpha=a,fit_intercept=True)\n",
    "    ridge.fit(X_train,Y_train)\n",
    "    coef.append(ridge.coef_)\n",
    "ax = plt.gca()\n",
    "ax.plot(alphas, coef)\n",
    "ax.set_xscale('log')\n",
    "plt.title('Ridge Regression')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Part 3 Lasso Plot\n",
    "coef = []\n",
    "for a in alphas:\n",
    "    lasso = linear_model.Lasso(alpha=a,fit_intercept=True)\n",
    "    lasso.fit(X_train,Y_train)\n",
    "    coef.append(lasso.coef_)\n",
    "ax = plt.gca()\n",
    "ax.plot(alphas, coef)\n",
    "ax.set_xscale('log')\n",
    "plt.title('Lasso Regression')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What do you qualitatively observe when the value of the regularization parameter changes (2pts)?\n",
    "The lasso model penalizes the high coefficient values as the alpha value increases. The ridge model differs because as the alpha increases and the coefficients reach zero, the model never sets the value of the coefficient to zero. This leads to low variance and low bias in the ridge model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Serial No.\n",
       "204    2.637944\n",
       "265    2.117000\n",
       "339    2.247908\n",
       "262    2.033991\n",
       "217    2.484323\n",
       "         ...   \n",
       "133    2.033991\n",
       "290    2.203396\n",
       "110    1.973878\n",
       "396    2.270500\n",
       "177    2.459603\n",
       "Name: Chance_of_Admit, Length: 300, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Part 4 \n",
    "_y_train = np.exp(Y_train)\n",
    "_y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exponential Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso Exponential - Best Alpha: 0.0018738174228603867\n",
      "Lasso Exponential - Min MSE: 0.01476731964422993\n"
     ]
    }
   ],
   "source": [
    "### Part 4 Exponential Lasso\n",
    "lasso_dict_exp = {}\n",
    "\n",
    "for a in alphas:\n",
    "    alpha_list = []\n",
    "    for train_index, test_index in kf.split(X_train):\n",
    "        x_train, x_test = X_train[train_index], X_train[test_index]\n",
    "        y_train, y_test = _y_train.iloc[train_index], _y_train.iloc[test_index]\n",
    "\n",
    "        clf = linear_model.Lasso(random_state=50, max_iter=10000, alpha = a)\n",
    "        clf = clf.fit(x_train, y_train)\n",
    "\n",
    "        mse = mean_squared_error(y_test, clf.predict(x_test))\n",
    "        alpha_list.append(mse)\n",
    "    avg = sum(alpha_list) / len(alpha_list)\n",
    "    lasso_dict_exp[a]= avg\n",
    "\n",
    "best_key_lasso_exp = min(lasso_dict_exp, key=lasso_dict_exp.get)\n",
    "print(\"Lasso Exponential - Best Alpha:\", best_key_lasso_exp)\n",
    "print(\"Lasso Exponential - Min MSE:\", min(lasso_dict_exp.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exponential Ridge "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Exponential - Best Alpha: 6.135907273413176\n",
      "Ridge Exponential - Min MSE: 0.014815008775351052\n"
     ]
    }
   ],
   "source": [
    "### Part 4 Exponential Ridge \n",
    "ridge_dict_exp = {}\n",
    "\n",
    "for a in alphas:\n",
    "    alpha_list = []\n",
    "    for train_index, test_index in kf.split(X_train):\n",
    "        x_train, x_test = X_train[train_index], X_train[test_index]\n",
    "        y_train, y_test = _y_train.iloc[train_index], _y_train.iloc[test_index]\n",
    "\n",
    "        clf = linear_model.Ridge(random_state=50, max_iter=10000, alpha = a)\n",
    "        clf = clf.fit(x_train, y_train)\n",
    "\n",
    "        mse = mean_squared_error(y_test, clf.predict(x_test))\n",
    "        alpha_list.append(mse)\n",
    "    avg = sum(alpha_list) / len(alpha_list)\n",
    "    ridge_dict_exp[a]= avg\n",
    "\n",
    "best_key_ridge_exp = min(ridge_dict_exp, key=ridge_dict_exp.get)\n",
    "print('Ridge Exponential - Best Alpha:',best_key_ridge_exp)\n",
    "print('Ridge Exponential - Min MSE:', min(ridge_dict_exp.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Compare the results of using the original target with the results of using the exponential of the target. What do you observe?\n",
    "\n",
    "The best alpha for the exponential ridge model was 6.13 and the smallest MSE was 0.015. The best alpha for the exponential lasso model was 0.002 and the smallest MSE was 0.015. Compared to the models without using the exponential y-train as the target, the best alpha for the lasso model was 0.001 and the smallest MSE was 0.004. The originial ridge model's best alpha value was 4.64 and the smallest MSE was 0.004. \n",
    "\n",
    "The results show that for both the ridge and lasso models the best alpha obtained and the smallest MSE values were larger when the models used the exponential y-train values as the target. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elastic - Best Alpha: 0.002477076355991714\n",
      "Elastic - Min MSE: 0.0040989685872616175\n"
     ]
    }
   ],
   "source": [
    "### Part 5 ElasticNet\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "elastic_dict = {}\n",
    "\n",
    "for a in alphas:\n",
    "    alpha_list = []\n",
    "    for train_index, test_index in kf.split(X_train):\n",
    "        x_train, x_test = X_train[train_index], X_train[test_index]\n",
    "        y_train, y_test = Y_train.iloc[train_index], Y_train.iloc[test_index]\n",
    "\n",
    "        clf = linear_model.ElasticNet(random_state=50, max_iter=10000, alpha = a)\n",
    "        clf = clf.fit(x_train, y_train)\n",
    "\n",
    "        mse = mean_squared_error(y_test, clf.predict(x_test))\n",
    "        alpha_list.append(mse)\n",
    "    avg = sum(alpha_list) / len(alpha_list)\n",
    "    elastic_dict[a]= avg\n",
    "\n",
    "best_key_elastic = min(elastic_dict, key=elastic_dict.get)\n",
    "print('Elastic - Best Alpha:',best_key_elastic)\n",
    "print('Elastic - Min MSE:',min(elastic_dict.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observe the plot, then explain the pros and cons of ridge, lasso and Elastic Net models (3pts).\n",
    "Ridge regression leads to low variance and low bias by reducing the dependency of any one variabe for prediction but since it does not reduce the number of variables, this model is not the best for feature reduction. The Lasso regression model selects only important features by reducing the irrelevant features to zero which helps avoid overfitting. The disadvantage is that given multiple highly collinear variables, the model will only choose one when all might be important. Elastic net is a combination of both Lasso and Ridge which means that the model will keep all high collinear variables but this model is computationally more expensive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression No Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression without Regularization MSE: 0.005200215496311308\n",
      "Linear Regression without Regularization R2: 0.6910288907914793\n"
     ]
    }
   ],
   "source": [
    "### Part 6 Linear Regression\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "lm = linear_model.LinearRegression().fit(X_train,Y_train)\n",
    "print('Linear Regression without Regularization MSE:',mean_squared_error(Y_test, lm.predict(X_test)))\n",
    "print('Linear Regression without Regularization R2:',r2_score(Y_test, lm.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso With Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression with Lasso Regularization MSE: 0.005169728551461909\n",
      "Linear Regression with Lasso Regularization R2: 0.6928402744107118\n"
     ]
    }
   ],
   "source": [
    "### Part 6 Lasso \n",
    "lasso = linear_model.Lasso(alpha=best_key_lasso).fit(X_train,Y_train)\n",
    "print('Linear Regression with Lasso Regularization MSE:',mean_squared_error(Y_test, lasso.predict(X_test)))\n",
    "print('Linear Regression with Lasso Regularization R2:',r2_score(Y_test, lasso.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge With Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression with Ridge Regularization MSE: 0.005145734926702875\n",
      "Linear Regression with Ridge Regularization R2: 0.6942658570353147\n"
     ]
    }
   ],
   "source": [
    "### Part 6 Ridge\n",
    "ridge = linear_model.Ridge(alpha=best_key_ridge).fit(X_train,Y_train)\n",
    "print('Linear Regression with Ridge Regularization MSE:',mean_squared_error(Y_test, ridge.predict(X_test)))\n",
    "print('Linear Regression with Ridge Regularization R2:',r2_score(Y_test, ridge.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression No Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE Linear Model No Scale: 0.004526319242200028\n",
      "R2 Linear Model No Scale: 0.7310684763186412\n"
     ]
    }
   ],
   "source": [
    "### Part 7 Linear Model No Scale\n",
    "\n",
    "X_train2, X_test2, Y_train2, Y_test2 = train_test_split(X, y, test_size=0.25, random_state=50)\n",
    "\n",
    "lm = linear_model.LinearRegression().fit(X_train2,Y_train2)\n",
    "print('MSE Linear Model No Scale:',mean_squared_error(Y_test2, lm.predict(X_test2)))\n",
    "print('R2 Linear Model No Scale:',r2_score(Y_test2, lm.predict(X_test2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso No Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Lasso Alpha No Scale: 0.0006135907273413163\n",
      "MSE Lasso Model No Scale: 0.004554495972017523\n",
      "R2 Lasso Model No Scale: 0.7293943542612467\n"
     ]
    }
   ],
   "source": [
    "### Part 7 Lasso Model No Scale\n",
    "\n",
    "alphas = 10**np.linspace(6,-6,100)\n",
    "lasso_dict = {}\n",
    "\n",
    "for a in alphas:\n",
    "    alpha_list = []\n",
    "    for train_index, test_index in kf.split(X_train2):\n",
    "        x_train2, x_test2 = X_train2.iloc[train_index], X_train2.iloc[test_index]\n",
    "        y_train2, y_test2 = Y_train2.iloc[train_index], Y_train2.iloc[test_index]\n",
    "\n",
    "        clf = linear_model.Lasso(random_state=50, max_iter=10000, alpha = a)\n",
    "        clf = clf.fit(x_train2, y_train2)\n",
    "\n",
    "        mse = mean_squared_error(y_test2, clf.predict(x_test2))\n",
    "        alpha_list.append(mse)\n",
    "    avg = sum(alpha_list) / len(alpha_list)\n",
    "    lasso_dict[a]= avg\n",
    "\n",
    "best_key_lasso_no_scale = min(lasso_dict, key=lasso_dict.get)\n",
    "print(\"Best Lasso Alpha No Scale:\", best_key_lasso_no_scale)\n",
    "\n",
    "lasso = linear_model.Lasso(alpha=best_key_lasso_no_scale).fit(X_train2,Y_train2)\n",
    "print('MSE Lasso Model No Scale:',mean_squared_error(Y_test2, lasso.predict(X_test2)))\n",
    "print('R2 Lasso Model No Scale:',r2_score(Y_test2, lasso.predict(X_test2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge No Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Ridge Alpha No Scale: 756463.3275546291\n",
      "MSE Ridge No Scale: 0.015700682098639243\n",
      "R2 Ridge No Scale: 0.06714305074704052\n"
     ]
    }
   ],
   "source": [
    "### Part 7 Ridge Regression No Scale\n",
    "alphas = 10**np.linspace(6,-6,100)\n",
    "ridge_dict = {}\n",
    "\n",
    "for a in alphas:\n",
    "    alpha_list = []\n",
    "    for train_index, test_index in kf.split(X_train2):\n",
    "        x_train2, x_test2 = X_train2.iloc[train_index], X_train2.iloc[test_index]\n",
    "        y_train2, y_test2 = Y_train2.iloc[train_index], Y_train2.iloc[test_index]\n",
    "\n",
    "        clf = linear_model.Ridge(random_state=50, max_iter=10000, alpha = a)\n",
    "        clf = clf.fit(x_train, y_train2)\n",
    "\n",
    "        mse = mean_squared_error(y_test, clf.predict(x_test2))\n",
    "        alpha_list.append(mse)\n",
    "    avg = sum(alpha_list) / len(alpha_list)\n",
    "    ridge_dict[a]= avg\n",
    "\n",
    "best_key_ridge_no_scale = min(ridge_dict, key=ridge_dict.get)\n",
    "print(\"Best Ridge Alpha No Scale:\",best_key_ridge_no_scale)\n",
    "\n",
    "ridge = linear_model.Ridge(alpha=best_key_ridge_no_scale).fit(X_train2,Y_train2)\n",
    "print('MSE Ridge No Scale:',mean_squared_error(Y_test2, ridge.predict(X_test2)))\n",
    "print('R2 Ridge No Scale:',r2_score(Y_test2, ridge.predict(X_test2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Why do we need to scale the data before regularization (2pts)?\n",
    "We need to scale the data before regularization to ensure that the features use values that are in similiar ranges. This ensures that features that are deemed as outliers are not used in the model. This is evident in the ridge model with scaling vs no scaling. In the ridge model with scaling the R2 is higher meaning there is higher correlation between the features and the MSE is smaller meaning there is less error in the model. This is an example where scaling the data is important before regularization."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "MIS 382N - HW1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
